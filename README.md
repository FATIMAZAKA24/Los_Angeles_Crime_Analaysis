# Los_Angeles_Crime_Analaysis
Cracking the Code on LA Crime:A modular Python framework for crime data engineering, victim profiling, and interactive spatial analysis.


**ğŸ•µï¸â€â™€ï¸ LA Crime Pattern Analysis**

A Complete Data Cleaning Pipeline + Exploratory Crime Pattern Study

**ğŸ“Œ Project Overview**

This project analyzes crime patterns in Los Angeles using the public dataset from Kaggle. The objective was not only to perform exploratory analysis, but to:

* Build a structured and reusable preprocessing pipeline
* Make principled decisions about missing data
* Engineer meaningful features
* Modularize the workflow into reusable Python files
* Extract actionable crime insights

This repository reflects a full data science workflow â€” from raw dataset to analysis-ready insights.

**ğŸ“‚ Dataset**

Source: Kaggle â€“ Los Angeles Crime Dataset

Data includes:
* Crime codes and descriptions
* Victim demographics
* Geographic information (Area, LAT, LON)
* Weapon information
* Date and time of occurrence
* Case status

**ğŸ— Project Architecture**

Los_Angeles_Crime_Analysis/
â”‚
â”œâ”€â”€ LA_Crime_Cleaned_Data.py      # Reusable preprocessing pipeline
â”œâ”€â”€ main_crime_analysis.py        # Main analysis file
â”œâ”€â”€ crime_bubble_map.py           # Geospatial visualization
â”œâ”€â”€ victim_profiling.py           # Victim segmentation analysis
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ night_crime_bubble_map.html
â”‚   â”œâ”€â”€ victim_hourly.json
â”‚   â”œâ”€â”€ victim_dashboard.html
â”‚   â”œâ”€â”€ victim_profiles.json
â”‚
â””â”€â”€ README.md

**ğŸ§¹ Data Cleaning & Preprocessing Strategy**

Raw datasets are rarely analysis-ready. Significant preprocessing was performed:

**ğŸ”¹ Columns Dropped**
| Column         | Reason                                  |
| -------------- | --------------------------------------- |
| DR_NO          | Case ID only; no analytical value       |
| Part 1-2       | Ambiguous                               |
| Mocodes        | 14% missing + multiple values per row   |
| Crm Cd 2, 3, 4 | High missing values                     |
| Cross Street   | Sparse and not useful for this analysis |

**ğŸ”¹ Missing Data Handling**

**Vict Sex (14% missing)**
Kept column for profiling purposes.

Handled via:
* Filling with "Unknown" for exploration
* Option to test predictive imputation

**Weapon Used (65% missing)**
**When missing values exceed 50%, traditional imputation becomes risky.*

Instead of:
* Mode imputation (biased)
* Predictive imputation (unstable)

Missing values were treated as a meaningful "Unknown" category.

**ğŸ”¹ Date & Time Transformations**

* Converted Date Occurred and Date Reported to proper datetime format
* Removed meaningless time components from date-only entries
* Extracted month from occurrence date
* Converted 24-hour military time into standard 12-hour format


**ğŸ”¹ Feature Engineering**

* Created age group segmentation
* Added descriptive column for Vict Descent codes
* Extracted month for seasonal pattern analysis
* Preserved encoded AREA column for ML compatibility


**ğŸ§  Key Analytical Questions**

The project answers:

* Which hour has the highest crime frequency?
* Which area has the most night crimes?
* Which age groups are targeted most frequently?
* What is the relationship between crime type and location?
* Which crimes show long reporting delays?


**ğŸ“ Geospatial Analysis**

A bubble map visualization was created using LAT and LON coordinates and exported as an interactive .html file.

**ğŸ”„ Modular Preprocessing**

The entire cleaning logic was stored in cleaning.py as a reusable function.

Benefits:
* Reproducibility
* Maintainability
* Scalability

Easy integration into ML workflows

**ğŸ§© Skills Demonstrated**

* Exploratory Data Analysis (EDA)
* Data Cleaning & Transformation
* Missing Data Strategy
* Feature Engineering
* Modular Python Development
* Geospatial Visualization
* Analytical Storytelling

**ğŸš€ Future Extensions**

* Predictive modeling
* Crime forecasting
* Area clustering
* Risk scoring models

**âœï¸ Author**

Fatima Zaka
Data Analysis Project â€“ 2026

